<!DOCTYPE html>
<html style="background-color:black ;">
    <head>
        <title>
            COVID-19</title>
            <center><h1 style="color:antiquewhite;font-size: 1cm;"><u>Models Vs. Evidence</u></h1></center>
            <style>
                .dropdown {
                      position: relative;
                      display: inline-block;
                                 }
            </style>
        
    </head>
    <body>
        
        <center><img src="covid1.jpg" height="300" width="500"></center> 
        <div class="dropdown" style="float: center;position: sticky;top: 0cm;">
        <center><img style="position: sticky;top: 0cm;" src="covid2.jpg " height="75" width="600"></center></div>
        <p style="font-family:cursive;color: white;">The lasting icon of the COVID-19 pandemic will likely be the graphic 
        associated with “flattening the curve.” The image is now familiar: a skewed
         bell curve measuring coronavirus cases that towers above a horizontal line—the 
         health system’s capacity—only to be flattened by an invisible force representing 
         “non-pharmaceutical interventions” such as school closures, social distancing, and full-on lockdowns.</p>
         <p style="font-family: cursive;color: white;">
            How do the coronavirus models generating these hypothetical curves square with the evidence? 
            What roles do models and evidence play in a pandemic? Answering these questions requires reconciling
             two competing philosophies in the science of COVID-19.
         </p>
         <p style="font-family: cursive;color: white;">
            In one camp are infectious disease epidemiologists, who work very closely with institutions of public health.
             They have used a multitude of models to create virtual worlds in which sim viruses wash over sim populations—
             sometimes unabated, sometimes held back by a virtual dam of social interventions. This deluge of simulated 
             outcomes played a significant role in leading government actors to shut borders as well as doors to schools 
             and businesses. But the hypothetical curves are smooth, while real-world data are rough. Some detractors have 
             questioned whether we have good evidence for the assumptions the models rely on, and even the necessity of the 
             dramatic steps taken to curb the pandemic. Among this camp are several clinical epidemiologists, who typically 
             provide guidance for clinical practice—regarding, for example, the effectiveness of medical interventions—rather
              than public health.
         </p>
         <p style="font-family: cursive;color: white;">
            The latter camp has won significant media attention in recent weeks. Bill Gates—whose foundation funds the research
             behind the most visible outbreak model in the United States, developed by the Institute for Health Metrics and 
             Evaluation (IHME) at the University of Washington—worries that COVID-19 might be a “once-in-a-century pandemic.” 
             A notable detractor from this view is Stanford’s John Ioannidis, a clinical epidemiologist, meta-researcher, and 
             reliable skeptic who has openly wondered whether the coronavirus pandemic might rather be a “once-in-a-century evidence 
             fiasco.” He argues that better data are needed to justify the drastic measures undertaken to contain the pandemic in the
              United States and elsewhere.
         </p>
         <p style="font-family: cursive;color: white;">
            Ioannidis claims, in particular, that our data about the pandemic are unreliable, leading to exaggerated estimates of risk.
             He also points to a systematic review published in 2011 of the evidence regarding physical interventions that aim to 
             reduce the spread of respiratory viruses, worrying that the available evidence is nonrandomized and prone to bias.
              (A systematic review specific to COVID-19 has now been published; it concurs that the quality of evidence is “low”
               to “very low” but nonetheless supports the use of quarantine and other public health measures.) According to Ioannidis,
                the current steps we are taking are “non-evidence-based.”
         </p>
         <p style="font-family: cursive;color: white;">
            This talk of “biased evidence” and “evidence-based interventions” is characteristic of the evidence-based medicine (EBM) 
            community, a close relative of clinical epidemiology. In a series of blog posts, for example, Tom Jefferson and Carl Heneghan
             of the Oxford Centre for Evidence-Based Medicine similarly lament the poor-quality data and evidence guiding action in the 
             pandemic and even suggest that lockdown is the wrong call.
         </p>
         <p style="font-family: cursive;color: white;">
            In the other corner, Harvard’s Marc Lipsitch, an infectious disease epidemiologist, agrees that we lack good data in many
             respects. Countering Ioannidis’s hesitation, however, Lipsitch responds: “We know enough to act; indeed, there is an 
             imperative to act strongly and swiftly.” According to this argument, we could not afford to wait for better data when the 
             consequences of delaying action are disastrous, and did have reason enough to act decisively.
         </p>
         <p style="font-family: cursive;color: white;">
            Public health epidemiologists and clinical epidemiologists have overlapping methods and expertise; they all seek to improve
             health by studying populations. Yet to some extent, public health epidemiology and clinical epidemiology are distinct 
             traditions in health care, competing philosophies of scientific knowledge. Public health epidemiology, including infectious
              disease epidemiology, tends to embrace theory and diversity of data; it is methodologically liberal and pragmatic. Clinical
               epidemiology, by contrast, tends to champion evidence and quality of data; it is comparatively more methodologically 
               conservative and skeptical. 
         </p>
         <p style="font-family: cursive;color: white;">
            To be clear, these comparisons are fair only writ large; they describe disciplinary orthodoxy as a whole rather than the 
            work of any given epidemiologist. Still, it is possible to discern two distinct philosophies in epidemiology, and both have 
            something to offer in the coronavirus crisis over models and evidence. A deeper understanding of modeling and evidence is the
             key not only to reconciling these divergent scientific mindsets but also to resolving the crisis.


         </p>
         
    </body>
</html>